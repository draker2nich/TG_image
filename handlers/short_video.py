from datetime import datetime
from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.fsm.context import FSMContext

from states.generation_states import ShortVideoStates
from keyboards.menus import (
    cancel_kb, video_model_kb, video_mode_kb, 
    aspect_ratio_kb, confirm_edit_kb, back_to_menu_kb
)
from services.kieai_service import kieai_service
from services.openai_service import openai_service
from services.task_tracker import task_tracker, VideoTask

router = Router()

# –ü–ª–∞—Ç—Ñ–æ—Ä–º—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º TikTok, Instagram, YouTube)
VIDEO_PLATFORMS = ["tiktok", "instagram", "youtube"]

@router.callback_query(F.data == "menu:short_video")
async def start_video_flow(callback: CallbackQuery, state: FSMContext):
    """–ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –≤–∏–¥–µ–æ"""
    if not kieai_service.is_available():
        await callback.message.edit_text(
            "‚ö†Ô∏è Kie.ai API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω.\n–î–æ–±–∞–≤—å—Ç–µ KIEAI_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.",
            reply_markup=back_to_menu_kb()
        )
        await callback.answer()
        return
    
    await state.set_state(ShortVideoStates.selecting_model)
    await callback.message.edit_text(
        "üé¨ <b>–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –≤–∏–¥–µ–æ</b>\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:\n\n"
        "üé• <b>Sora 2</b> ‚Äî –º–æ–¥–µ–ª—å –æ—Ç OpenAI\n"
        "‚ö° <b>Veo 3.1 Fast</b> ‚Äî –±—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
        "üíé <b>Veo 3.1 Quality</b> ‚Äî –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ",
        parse_mode="HTML",
        reply_markup=video_model_kb()
    )
    await callback.answer()

@router.callback_query(ShortVideoStates.selecting_model, F.data.startswith("model:"))
async def select_model(callback: CallbackQuery, state: FSMContext):
    """–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏"""
    model = callback.data.split(":")[1]
    await state.update_data(model=model)
    await state.set_state(ShortVideoStates.selecting_mode)
    
    await callback.message.edit_text(
        "üìπ <b>–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:</b>\n\n"
        "üìù <b>–¢–µ–∫—Å—Ç ‚Üí –í–∏–¥–µ–æ</b>\n"
        "üñº <b>–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ‚Üí –í–∏–¥–µ–æ</b>",
        parse_mode="HTML",
        reply_markup=video_mode_kb()
    )
    await callback.answer()

@router.callback_query(ShortVideoStates.selecting_mode, F.data == "back:model")
async def back_to_model(callback: CallbackQuery, state: FSMContext):
    """–í–æ–∑–≤—Ä–∞—Ç –∫ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏"""
    await state.set_state(ShortVideoStates.selecting_model)
    await callback.message.edit_text(
        "üé¨ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        reply_markup=video_model_kb()
    )
    await callback.answer()

@router.callback_query(ShortVideoStates.selecting_mode, F.data.startswith("mode:"))
async def select_mode(callback: CallbackQuery, state: FSMContext):
    """–í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ (t2v –∏–ª–∏ i2v)"""
    mode = callback.data.split(":")[1]
    await state.update_data(mode=mode)
    
    if mode == "t2v":
        await state.set_state(ShortVideoStates.waiting_prompt)
        await callback.message.edit_text(
            "‚úçÔ∏è <b>–û–ø–∏—à–∏—Ç–µ –∏–¥–µ—é –≤–∏–¥–µ–æ –∫—Ä–∞—Ç–∫–æ</b>\n\n"
            "–û–ø–∏—à–∏—Ç–µ —Å—É—Ç—å ‚Äî –ø—Ä–æ–º–ø—Ç –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ª—É—á—à–µ–Ω\n",
            parse_mode="HTML",
            reply_markup=cancel_kb()
        )
    else:  # i2v
        await state.set_state(ShortVideoStates.waiting_image)
        await callback.message.edit_text(
            "üñº <b>–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ</b>\n\n"
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ, –∫–æ—Ç–æ—Ä–æ–µ –Ω—É–∂–Ω–æ –∞–Ω–∏–º–∏—Ä–æ–≤–∞—Ç—å.",
            parse_mode="HTML",
            reply_markup=cancel_kb()
        )
    await callback.answer()

@router.message(ShortVideoStates.waiting_prompt)
async def process_prompt(message: Message, state: FSMContext):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –∏ –µ–≥–æ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤"""
    user_idea = message.text.strip()
    await state.update_data(original_prompt=user_idea)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±–∞–∑—ã –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    import os
    import json
    COMPETITORS_FILE = os.path.join("knowledge_base", "competitors.json")
    
    has_competitors = False
    if os.path.exists(COMPETITORS_FILE):
        try:
            with open(COMPETITORS_FILE, 'r', encoding='utf-8') as f:
                competitors = json.load(f)
            for platform in VIDEO_PLATFORMS:
                if competitors.get(platform, []):
                    has_competitors = True
                    break
        except:
            pass
    
    # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ OpenAI —Å —É—á–µ—Ç–æ–º –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤
    if openai_service.is_available():
        status_parts = ["‚è≥ –£–ª—É—á—à–∞—é –ø—Ä–æ–º–ø—Ç..."]
        status_parts.append("\nüìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: —É—á—Ç–µ–Ω–∞")
        if has_competitors:
            status_parts.append("üéØ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é")
        
        await message.answer("".join(status_parts))
        
        try:
            enhanced = await openai_service.enhance_video_prompt(
                user_prompt=user_idea,
                platforms=VIDEO_PLATFORMS
            )
            await state.update_data(prompt=enhanced)
            await state.set_state(ShortVideoStates.selecting_aspect)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
            info_text = "‚ú® <b>–ü—Ä–æ–º–ø—Ç —É–ª—É—á—à–µ–Ω!</b>\n\n"
            if has_competitors:
                info_text += "‚úÖ –£—á—Ç—ë–Ω –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤\n"
            info_text += "\n‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π\n\n"
            info_text += f"<b>–§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç:</b>\n<code>{enhanced}</code>\n\n"
            info_text += "–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω:"
            
            await message.answer(
                info_text,
                parse_mode="HTML",
                reply_markup=aspect_ratio_kb()
            )
        except Exception as e:
            # Fallback –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            await state.update_data(prompt=user_idea)
            await state.set_state(ShortVideoStates.selecting_aspect)
            await message.answer(
                f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–º–ø—Ç: {e}\n\n"
                "–ò—Å–ø–æ–ª—å–∑—É—é –∏—Å—Ö–æ–¥–Ω—É—é –∏–¥–µ—é. –í—ã–±–µ—Ä–∏—Ç–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω:",
                reply_markup=aspect_ratio_kb()
            )
    else:
        # –ï—Å–ª–∏ OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        await state.update_data(prompt=user_idea)
        await state.set_state(ShortVideoStates.selecting_aspect)
        await message.answer(
            "‚ö†Ô∏è OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –ø—Ä–æ–º–ø—Ç –Ω–µ –±—É–¥–µ—Ç —É–ª—É—á—à–µ–Ω.\n\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω:",
            reply_markup=aspect_ratio_kb()
        )

@router.message(ShortVideoStates.waiting_image, F.photo)
async def process_image(message: Message, state: FSMContext):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    photo = message.photo[-1]  # –ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    file = await message.bot.get_file(photo.file_id)
    file_url = f"https://api.telegram.org/file/bot{message.bot.token}/{file.file_path}"
    
    await state.update_data(image_url=file_url)
    await state.set_state(ShortVideoStates.waiting_prompt)
    
    await message.answer(
        "‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ!\n\n"
        "‚úçÔ∏è –¢–µ–ø–µ—Ä—å –∫—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏—Ç–µ, –∫–∞–∫ –¥–æ–ª–∂–Ω–æ –∞–Ω–∏–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:\n\n",
        parse_mode="HTML",
        reply_markup=cancel_kb()
    )

@router.message(ShortVideoStates.waiting_image)
async def process_image_invalid(message: Message):
    """–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–≤–æ–¥ –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    await message.answer("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.", reply_markup=cancel_kb())

@router.callback_query(ShortVideoStates.selecting_aspect, F.data == "back:mode")
async def back_to_mode(callback: CallbackQuery, state: FSMContext):
    """–í–æ–∑–≤—Ä–∞—Ç –∫ –≤—ã–±–æ—Ä—É —Ä–µ–∂–∏–º–∞"""
    await state.set_state(ShortVideoStates.selecting_mode)
    await callback.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:", reply_markup=video_mode_kb())
    await callback.answer()

@router.callback_query(ShortVideoStates.selecting_aspect, F.data.startswith("aspect:"))
async def select_aspect_and_generate(callback: CallbackQuery, state: FSMContext):
    """–í—ã–±–æ—Ä —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω –∏ –∑–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    aspect = callback.data.split(":", 1)[1]  # "16:9" –∏–ª–∏ "9:16"
    data = await state.get_data()
    
    model = data["model"]
    mode = data["mode"]
    prompt = data["prompt"]
    image_url = data.get("image_url")
    original_idea = data.get("original_prompt", prompt)
    
    await state.set_state(ShortVideoStates.generating)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—É—Å–∫–µ
    info_parts = ["üé¨ –ó–∞–ø—É—Å–∫–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–¥–µ–æ...\n"]
    info_parts.append(f"üìù –ò—Å—Ö–æ–¥–Ω–∞—è –∏–¥–µ—è: {original_idea[:100]}\n")
    if prompt != original_idea:
        info_parts.append("‚ú® –ü—Ä–æ–º–ø—Ç —É–ª—É—á—à–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤")
    
    await callback.message.edit_text("".join(info_parts))
    
    try:
        if model == "sora2":
            # Sora 2
            sora_aspect = "landscape" if aspect == "16:9" else "portrait"
            result = await kieai_service.generate_sora2_video(
                prompt=prompt,
                mode="image" if image_url else "text",
                image_urls=[image_url] if image_url else None,
                aspect_ratio=sora_aspect
            )
        else:
            # Veo 3.1
            result = await kieai_service.generate_veo3_video(
                prompt=prompt,
                model=model,
                image_urls=[image_url] if image_url else None,
                aspect_ratio=aspect
            )
        
        if result.get("code") != 200:
            raise Exception(result.get("msg", "Unknown error"))
        
        task_id = result.get("data", {}).get("taskId")
        if not task_id:
            raise Exception("–ù–µ –ø–æ–ª—É—á–µ–Ω taskId")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Ç—Ä–µ–∫–µ—Ä –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
        video_task = VideoTask(
            task_id=task_id,
            chat_id=callback.message.chat.id,
            user_id=callback.from_user.id,
            model=model,
            created_at=datetime.now(),
            prompt=original_idea  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∏–¥–µ—é –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        )
        task_tracker.add_task(video_task)
        
        model_name = {"sora2": "Sora 2", "veo3_fast": "Veo 3.1 Fast", "veo3": "Veo 3.1 Quality"}
        
        await callback.message.edit_text(
            f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞!\n\n"
            f"üé¨ –ú–æ–¥–µ–ª—å: {model_name.get(model, model)}\n"
            f"üìù –ò–¥–µ—è: {original_idea[:100]}\n"
            f"üÜî Task ID: <code>{task_id}</code>\n\n"
            f"‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç 2-15 –º–∏–Ω—É—Ç.\n"
            f"üì© –í–∏–¥–µ–æ –ø—Ä–∏–¥—ë—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤–æ!",
            parse_mode="HTML",
            reply_markup=back_to_menu_kb()
        )
        await state.clear()
        
    except Exception as e:
        await callback.message.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}", reply_markup=back_to_menu_kb())
        await state.clear()
    
    await callback.answer()